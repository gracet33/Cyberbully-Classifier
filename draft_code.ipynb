{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e12980-5f2e-4c4e-92dd-f4c982d7eb1b",
   "metadata": {},
   "source": [
    "# Cyberbullying Classification by Type\n",
    "The objective of this work is to create a multi-label classification model to classify the text according to a set of cyberbullying types - Sexual_Type1, Sexual_Type2, Physical_Appearance, Race, Intellectual, Religious, General Hate, and Neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955fa56-0da2-4536-8ffa-c42f86856e1b",
   "metadata": {},
   "source": [
    "## Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbd4533-a9a0-4d00-b9db-8b456f8ac62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Albert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "stopwords_default=stopwords.words('english')\n",
    "\n",
    "from appos.appos import appos_dict\n",
    "from slangs.slangs import slangs_dict\n",
    "from emoticons.emoticons import emoticons\n",
    "\n",
    "from langdetect import detect\n",
    "from translate import Translator\n",
    "from spellchecker import SpellChecker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d9441-c3dd-4d4e-bf7c-abf48a840586",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "The process to extract data from a given .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a623ace-c51a-4fbf-94b9-5d48a77c0041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the folder path to the location of original dataset\n",
    "folder_path = r\"./Dataset/\"\n",
    "\n",
    "# Create an empty list for storing the created dataframe from original dataset\n",
    "filtered_dfs = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Read only files with name ends with .xlsx\n",
    "    if filename.endswith('.xlsx'):\n",
    "        excel_file = os.path.join(folder_path, filename)\n",
    "        xlsx = pd.ExcelFile(excel_file)\n",
    "        sheet_names = xlsx.sheet_names # Read the sheet names contain inside the excel file\n",
    "        dataframe = {}\n",
    "        defined_column_name = [\"Comment_Number\",\n",
    "                               \"Commenter_Username\",\n",
    "                               \"Comment\",\n",
    "                               \"Comment_Post_Time\",\n",
    "                               \"Overall_CB_Status\",\n",
    "                               \"CB_Type\",\n",
    "                               \"Sexual_Type1\", \"Unnamed_1\", \"Unnamed_2\",\n",
    "                               \"Sexual_Type2\", \"Unnamed_3\", \"Unnamed_4\",\n",
    "                               \"Physical_Appearance\", \"Unnamed_5\", \"Unnamed_6\",\n",
    "                               \"Race\", \"Unnamed_7\", \"Unnamed_8\",\n",
    "                               \"Intellectual\", \"Unnamed_9\", \"Unnamed_10\",\n",
    "                               \"Religious\", \"Unnamed_11\", \"Unnamed_12\",\n",
    "                               \"General_Hate\", \"Unnamed_13\", \"Unnamed_14\",\n",
    "                               \"Purpose_of_CB\",\n",
    "                               \"Insult\", \"Unnamed_15\", \"Unnamed_16\",\n",
    "                               \"Defensive\", \"Unnamed_17\", \"Unnamed_18\",\n",
    "                               \"Directionality\", \n",
    "                               \"Directed_Username\", \"Unnamed_19\", \"Unnamed_20\",\n",
    "                               \"Other_Aspects\",\n",
    "                               \"Depression\", \"Unnamed_21\", \"Unnamed_22\",\n",
    "                               \"Suicides\", \"Unnamed_23\", \"Unnamed_24\",\n",
    "                               \"Stress\", \"Unnamed_25\", \"Unnamed_26\",\n",
    "                               \"Discrimination\", \"Unnamed_27\", \"Unnamed_28\"]\n",
    "        \n",
    "        for sheet_name in sheet_names:\n",
    "            # Retrive the dataframe for that specific sheet name\n",
    "            dataframe[sheet_name] = pd.read_excel(excel_file, sheet_name)\n",
    "            \n",
    "            # Redefine the columns' name based on the defined_column_name\n",
    "            try:\n",
    "                dataframe[sheet_name].columns = defined_column_name\n",
    "            except:\n",
    "                print(f'{filename} : {sheet_name}.')\n",
    "                \n",
    "        \n",
    "        for item in dataframe.values():\n",
    "            # Drop the first two rows of the dataframe due to formatting issue\n",
    "            item = item.drop(item.index[:2])\n",
    "            \n",
    "            # Drop unnecessary attributes/columns from the dataframe\n",
    "            columns_to_drop = [col for col in item.columns if any(substring in col for substring in [\"Comment_Number\",\n",
    "                                                                                                     \"Unnamed\",\n",
    "                                                                                                     \"Commenter_Username\",\n",
    "                                                                                                     \"Comment_Post_Time\",\n",
    "                                                                                                     \"CB_Type\", \n",
    "                                                                                                     \"Purpose_of_CB\",\n",
    "                                                                                                     \"Insult\",\n",
    "                                                                                                     \"Religious\",\n",
    "                                                                                                     \"Defensive\",\n",
    "                                                                                                     \"Other_Aspects\",\n",
    "                                                                                                     'Suicides',\n",
    "                                                                                                     \"Stress\",\n",
    "                                                                                                     \"Depression\",\n",
    "                                                                                                     \"Discrimination\",\n",
    "                                                                                                     \"Directionality\", \n",
    "                                                                                                    \"Directed_Username\"])]\n",
    "\n",
    "            filter_df = item.drop(columns=columns_to_drop)\n",
    "            # Store the dataframe to filtered_dfs\n",
    "            filtered_dfs.append(filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9704b8f-c2ef-4b69-8259-780a99de4aba",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this stage, we are checking for the followings:\n",
    "* Remove any duplicates items in the 'Comment' columns\n",
    "* Missing values in the attributes, any missing values will be replaced by 0\n",
    "* Check for dataframe data types and perform data type conversion\n",
    "* Check for error data\n",
    "* Text formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d25be-c7c8-439b-88e1-acc5cef307d3",
   "metadata": {},
   "source": [
    "### Removal of Duplicates Data for 'Comments' attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358f5d8c-440f-4efb-a37f-019599db1274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate all the filtered dataframes into one\n",
    "df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "\n",
    "# Removal of duplicates items in the 'Comment' column\n",
    "df = df.drop_duplicates(subset='Comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded2e07-a0de-4e27-8581-9dbda5bbdcf8",
   "metadata": {},
   "source": [
    "### Replacing NA values with 0\n",
    "\n",
    "An assumption is made that the all the cyberbullying texts in the provided original datasets have been correctly labelled as 1. Therefore, the remaining data with NA values will be labelled as 0 which is not a cyberbullying text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21cbca8-6d2a-4665-ae59-d879472d81b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values found in the DataFrame. Replacing NA values with 0......\n",
      "No NA values founds in the datasets.\n"
     ]
    }
   ],
   "source": [
    "# Check NA value exists in the concatenated dataframe\n",
    "check_na = df.isna()\n",
    "max_retries = 2\n",
    "retry_count = 0\n",
    "\n",
    "# Replace NA value to 0 if presents in the dataframe\n",
    "while (check_na == True).any().any() and retry_count < max_retries:\n",
    "    print(\"NA values found in the DataFrame. Replacing NA values with 0......\")            \n",
    "    df = df.fillna(0)\n",
    "    check_na = df.isna()\n",
    "    retry_count += 1\n",
    "          \n",
    "if (check_na == True).any().any():\n",
    "    print(\"Maximum retries reached. Some NA values could not be replaced.\")\n",
    "else:\n",
    "    print(\"No NA values founds in the datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8f8a6-ee27-4228-bc29-e30eebf78a53",
   "metadata": {},
   "source": [
    "### Check for Attributes' Data Type\n",
    "According to the attributes' characteristics, all attributes should be in int (1 : True and 0 : False) with the exceptions for 'Comment' which should be in string/object type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1df901-5301-44e5-83ba-2173873ff992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment                object\n",
       "Overall_CB_Status       int64\n",
       "Sexual_Type1           object\n",
       "Sexual_Type2            int64\n",
       "Physical_Appearance     int64\n",
       "Race                   object\n",
       "Intellectual            int64\n",
       "General_Hate           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for dataframe's data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921717f1-4330-4762-b37e-3376ee7a46c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment                object\n",
      "Overall_CB_Status       int64\n",
      "Sexual_Type1            int64\n",
      "Sexual_Type2            int64\n",
      "Physical_Appearance     int64\n",
      "Race                    int64\n",
      "Intellectual            int64\n",
      "General_Hate            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "selected_column = ['Sexual_Type1', 'Race', 'General_Hate']\n",
    "\n",
    "# Performing data type conversion according to their attributes\n",
    "for column_name in selected_column:\n",
    "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce').fillna(0)\n",
    "    df[column_name] = df[column_name].astype('int64')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6302db1-55d2-40ef-b2f6-8094f7a28485",
   "metadata": {},
   "source": [
    "### Check for Error Data\n",
    "Since all attributes with the exception of 'Comments' are in int (1 : True, 0 : False), and thus the min and max value within the attribute should be either 0 or 1 only.\n",
    "\n",
    "Any error data will be removed from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d97bae4-22d9-4f34-a260-cfafd150bfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_CB_Status</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7943.00000</td>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7943.000000</td>\n",
       "      <td>7943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.134080</td>\n",
       "      <td>0.02883</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.019262</td>\n",
       "      <td>0.068362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.341867</td>\n",
       "      <td>0.16734</td>\n",
       "      <td>0.115287</td>\n",
       "      <td>0.137894</td>\n",
       "      <td>0.116345</td>\n",
       "      <td>0.137454</td>\n",
       "      <td>0.252382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Overall_CB_Status  Sexual_Type1  Sexual_Type2  Physical_Appearance  \\\n",
       "count        7943.000000    7943.00000   7943.000000          7943.000000   \n",
       "mean            0.134080       0.02883      0.013471             0.019388   \n",
       "std             0.341867       0.16734      0.115287             0.137894   \n",
       "min             0.000000       0.00000      0.000000             0.000000   \n",
       "25%             0.000000       0.00000      0.000000             0.000000   \n",
       "50%             0.000000       0.00000      0.000000             0.000000   \n",
       "75%             0.000000       0.00000      0.000000             0.000000   \n",
       "max             3.000000       1.00000      1.000000             1.000000   \n",
       "\n",
       "              Race  Intellectual  General_Hate  \n",
       "count  7943.000000   7943.000000   7943.000000  \n",
       "mean      0.013723      0.019262      0.068362  \n",
       "std       0.116345      0.137454      0.252382  \n",
       "min       0.000000      0.000000      0.000000  \n",
       "25%       0.000000      0.000000      0.000000  \n",
       "50%       0.000000      0.000000      0.000000  \n",
       "75%       0.000000      0.000000      0.000000  \n",
       "max       1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7c01e-0368-4f8f-90ee-0741d91c0a2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "For 'Overall_CB_Status' attribute, it contains value larger than 1. Therefore, the respective rows with value greater than 1 should be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dea886f-3de7-4a2f-8ece-72e2ac95a269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_CB_Status</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.133719</td>\n",
       "      <td>0.028834</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>0.068371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.340372</td>\n",
       "      <td>0.167350</td>\n",
       "      <td>0.115295</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>0.116352</td>\n",
       "      <td>0.137462</td>\n",
       "      <td>0.252397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Overall_CB_Status  Sexual_Type1  Sexual_Type2  Physical_Appearance  \\\n",
       "count        7942.000000   7942.000000   7942.000000          7942.000000   \n",
       "mean            0.133719      0.028834      0.013473             0.019391   \n",
       "std             0.340372      0.167350      0.115295             0.137902   \n",
       "min             0.000000      0.000000      0.000000             0.000000   \n",
       "25%             0.000000      0.000000      0.000000             0.000000   \n",
       "50%             0.000000      0.000000      0.000000             0.000000   \n",
       "75%             0.000000      0.000000      0.000000             0.000000   \n",
       "max             1.000000      1.000000      1.000000             1.000000   \n",
       "\n",
       "              Race  Intellectual  General_Hate  \n",
       "count  7942.000000   7942.000000   7942.000000  \n",
       "mean      0.013725      0.019265      0.068371  \n",
       "std       0.116352      0.137462      0.252397  \n",
       "min       0.000000      0.000000      0.000000  \n",
       "25%       0.000000      0.000000      0.000000  \n",
       "50%       0.000000      0.000000      0.000000  \n",
       "75%       0.000000      0.000000      0.000000  \n",
       "max       1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print rows where one of the attributes is equal to 3\n",
    "df = df[(df['Overall_CB_Status'] <= 1)]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996fcec-5874-430c-9c57-1f94c604ab04",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ff8c17-735b-43b8-8438-bc3781947d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_formatting = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9bf441-8bcc-42e0-8ff0-c49999abd144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_lower(text):\n",
    "    if isinstance (text, str):\n",
    "        lower_text = str(text.lower())\n",
    "    else:\n",
    "        lower_text = str(text)\n",
    "    return lower_text\n",
    "\n",
    "def appos_look_up(text):\n",
    "    \"\"\"\n",
    "    Convert apostrophes word to original form\n",
    "    Example: I don't know what is going on?  => I do not know what is going on? \n",
    "    Args:\n",
    "        text (str): text \n",
    "\n",
    "    Returns:\n",
    "        apposed (str) : text with converted apostrophes\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_text = []\n",
    "    for word in words:\n",
    "        word_s = word.lower()\n",
    "        if word_s in appos_dict:\n",
    "            new_text.append(appos_dict[word_s])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    apposed = \" \".join(new_text)\n",
    "    return apposed\n",
    "\n",
    "def remove_words_start_with(text, starts_with_char):\n",
    "    \"\"\"\n",
    "    Remove words start with character `starts_with_char`\n",
    "    Example: dhoni rocks with last ball six #dhoni #six => dhoni rocks with last ball six (start_char_with='#')\n",
    "    Args:\n",
    "        text (str): text\n",
    "        starts_with_char (str): starting characters of word, which to be removed from text\n",
    "\n",
    "    Returns:\n",
    "        text (str): text with removed words start with given chars\n",
    "    \"\"\"\n",
    "    urls = re.finditer(starts_with_char + r'[A-Za-z0-9\\w]*', text)\n",
    "    for i in urls:\n",
    "        text = re.sub(i.group().strip(), '', text)\n",
    "    return text.strip()\n",
    "\n",
    "def separate_digit_text(text):\n",
    "    \"\"\"\n",
    "    Separate digit and words with space in text\n",
    "    Example: I will be booking tickets for 2adults => I will be booking tickets for 2 adults   \n",
    "    Args:\n",
    "        text (str): text\n",
    "    Returns:\n",
    "        clean_text (str): cleaned text with separated digits and words\n",
    "    \"\"\"\n",
    "    regex_patter = re.compile(r'([\\d]+)([a-zA-Z]+)')\n",
    "    clean_text = regex_patter.sub(r'\\1 \\2', text)\n",
    "    return clean_text\n",
    "\n",
    "def slang_look_up(text):\n",
    "    \"\"\"\n",
    "    Replace slang word in text to their original form\n",
    "    Example: hi, thanq so mch => hi, thank you so much\n",
    "    Args:\n",
    "        text (str): text\n",
    "    Returns:\n",
    "        slanged (str): cleaned text with replaced slang\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_text = []\n",
    "\n",
    "    for word in words:\n",
    "        word_s = word.lower()\n",
    "        if word_s in slangs_dict:\n",
    "            new_text.append(slangs_dict[word_s])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    slanged = \" \".join(new_text)\n",
    "    return slanged\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    \"\"\"\n",
    "    Removed special characters from text\n",
    "    Example: he: I am going. are you coming? => he I am going. are you coming\n",
    "   \n",
    "    Args:\n",
    "        text (str): text\n",
    "   \n",
    "    Returns:\n",
    "        clean_text (str): cleaned text with removed special characters\n",
    "    \"\"\"\n",
    "    regex_pattern = re.compile(r'[\\,+\\:\\?\\!\\\"\\(\\)!\\'\\.\\%\\[\\]]+')\n",
    "    clean_text = regex_pattern.sub(r' ', text)\n",
    "    clean_text = clean_text.replace('-', '')\n",
    "    return clean_text\n",
    "\n",
    "def remove_extra_space(text):\n",
    "    \"\"\"\n",
    "    Remove extra white spaces space from text\n",
    "    Example: hey are   you coming. ? => he are you coming. ?\n",
    "    Args:\n",
    "        text (str): text\n",
    "    Returns:\n",
    "        clean_text (str): clean text with removed extra white spaces\n",
    "    \"\"\"\n",
    "    clean_text = ' '.join(text.strip().split())\n",
    "    return clean_text\n",
    "\n",
    "def emoticons_look_up(text):\n",
    "    \"\"\"\n",
    "    Remove emoticons from text and returns list of emotions present in text\n",
    "    Example: Sure, you are welcome :) => Sure, you are welcome.\n",
    "    Args:\n",
    "        text (str): text\n",
    "    Returns:\n",
    "        text (str): text with removed emoticons sign\n",
    "        emolist (list) : list of emotions from text\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in emoticons:\n",
    "            text = text.replace(word, emoticons[word])\n",
    "    return text\n",
    "\n",
    "def removal_non_letter_digit_whitespaces(text):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'  # Matches any character that is not a letter, digit, or whitespace\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def remove_single_char_word(text):\n",
    "    \"\"\"\n",
    "    Remove single character word from text\n",
    "    Example: I am in a home for 2 years => am in home for years \n",
    "    Args:\n",
    "        text (str): text\n",
    "         \n",
    "    Returns:\n",
    "        (str): text with single char removed\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    filter_words = [word for word in words if len(word) > 1]\n",
    "    return \" \".join(filter_words)\n",
    "\n",
    "def remove_repeated_characters(text):\n",
    "    \"\"\"\n",
    "    Remove repeated characters (>2) in words to max limit of 2\n",
    "    Example: I am verrry happpyyy today => I am verry happyy today\n",
    "    Args:\n",
    "        text (str): text\n",
    "\n",
    "    Returns:\n",
    "        clean_text (str): cleaned text with removed repeated chars\n",
    "    \"\"\"\n",
    "    regex_pattern = re.compile(r'(.)\\1+')\n",
    "    text = regex_pattern.sub(r'\\1\\1', text)\n",
    "    return text\n",
    "\n",
    "def removal_of_digits(text):\n",
    "    \"\"\"\n",
    "    Replace digits to `replace_char`\n",
    "    Example: I will be there on 22 april. => I will be there on dd april.\n",
    "    Args:\n",
    "        text (str): text\n",
    "        replace_char (str): character with which digit has to be replaced\n",
    "    Returns:\n",
    "        clean_text (str): clean text with replaced char for digits\n",
    "    \"\"\"\n",
    "    regex_pattern = re.compile(r'[0-9]')\n",
    "    text = regex_pattern.sub('', text)\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(text, stop_words=stopwords_default):\n",
    "    \"\"\"\n",
    "    This function removes stop words from text\n",
    "    Example: I am very excited for today's football match => very excited today's football match\n",
    "    Params\n",
    "        text (str) :text on which processing needs to done\n",
    "        stop_words (list) : stop words which needs to be removed\n",
    "    Returns\n",
    "        text(str): text after stop words removal\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = set(stopwords_default)\n",
    "    split_list = text.split(\" \")\n",
    "    split_list = [word for word in split_list if word not in stop_words]\n",
    "    return \" \".join(split_list)\n",
    "\n",
    "def auto_translate_to_english(text):\n",
    "    if any(char.isalpha() for char in text): \n",
    "        # Detect the language of the input text\n",
    "        detected_lang = detect(text)\n",
    "        # Check if the detected language is already English\n",
    "        if detected_lang == 'en':\n",
    "            return text  # No need to translate if it's already English\n",
    "        else:\n",
    "            # Initialize the Google Translator\n",
    "            translator = Translator(to_lang='en')\n",
    "\n",
    "            # Translate the text to English\n",
    "            translated_text = translator.translate(text)\n",
    "\n",
    "            return translated_text\n",
    "\n",
    "\n",
    "def check_word_spelling(text):\n",
    "    # Initialize the spell checker\n",
    "    spell = SpellChecker()\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    # Create a dictionary to store misspelled words and their corrected versions\n",
    "    misspelled_dict = {}\n",
    "\n",
    "    # Iterate through the words in the text\n",
    "    for word in words:\n",
    "        # Check if the word is misspelled\n",
    "        if word in spell.unknown(words):\n",
    "            # Get the one `most likely` correction\n",
    "            corrected_word = spell.correction(word)\n",
    "            # Store the misspelled word and its correction in the dictionary\n",
    "            misspelled_dict[word] = corrected_word\n",
    "\n",
    "    # Replace misspelled words with their corrected versions in the text\n",
    "    for misspelled, corrected in misspelled_dict.items():\n",
    "        if corrected is not None:\n",
    "            text = text.replace(misspelled, corrected)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_words_ending_with_com(text):\n",
    "    # Define a regular expression pattern to match words ending with \".com\"\n",
    "    pattern = r'\\b\\w+\\.com\\b'\n",
    "    # Use the re.sub function to replace all matches with an empty string\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Define a function to check if a string contains alphabets or numbers\n",
    "def contains_alphabets_or_numbers(text):\n",
    "    return any(char.isalpha() or char.isdigit() for char in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d47d66-420d-4c1d-9cc5-24fa8272cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : text_to_lower(x))\n",
    "\n",
    "starts_with_char_list = ['@', '#']\n",
    "for char in starts_with_char_list:\n",
    "    text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_words_start_with(x,starts_with_char=char))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_words_ending_with_com(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : appos_look_up(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : separate_digit_text(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : slang_look_up(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : emoticons_look_up(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_punctuations(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : removal_non_letter_digit_whitespaces(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_single_char_word(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_repeated_characters(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : removal_of_digits(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_stop_words(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_extra_space(x))\n",
    "text_formatting = text_formatting[text_formatting['Comment'].apply(contains_alphabets_or_numbers)]\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : auto_translate_to_english(x))\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : check_word_spelling(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "745468b5-a5e6-4c95-bbd2-472d3a48735f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_formating' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./preprocess_data_v0.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtext_formating\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_formating' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = './preprocess_data_v0.csv'\n",
    "text_formatting.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037787ec-4029-4191-9476-1f8a76bf63a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
