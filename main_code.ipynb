{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3ce917-4cc2-47d6-8fa5-8d47dcf95f20",
   "metadata": {},
   "source": [
    "# Cyberbullying Classification by Type\n",
    "The objective of this work is to create a multi-label classification model to classify the text according to a set of cyberbullying types - Sexual_Type1, Sexual_Type2, Physical_Appearance, Race, Intellectual, Religious and General Hate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b917d5-70df-4f7a-8037-de682422daba",
   "metadata": {},
   "source": [
    "# Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0da48865-6cd9-4780-9855-806beeeba152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Albert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Albert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from appos.appos import appos_dict\n",
    "from slangs.slangs import slangs_dict\n",
    "from emoticons.emoticons import emoticons\n",
    "from langdetect import detect\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import words\n",
    "nltk.download('words') # Download the English words corpus from nltk\n",
    "english_words = set(words.words())\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_default=stopwords.words('english') # To import the common stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42180b6-f5b6-4c04-a3cf-375529e6ff87",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Data Extraction\n",
    "To extract the data from the given .xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "36cc8e67-192b-468d-8f0e-a74b6976ded7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the folder path to the location of original dataset\n",
    "folder_path = r\"./Dataset/\"\n",
    "\n",
    "# Create an empty list for storing the created dataframe from original dataset\n",
    "extracted_df = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Read only files with name ends with .xlsx\n",
    "    if filename.endswith('.xlsx'):\n",
    "        excel_file = os.path.join(folder_path, filename)\n",
    "        xlsx = pd.ExcelFile(excel_file)\n",
    "        sheet_names = xlsx.sheet_names # Read the sheet names contain inside the excel file\n",
    "        dataframe = {}\n",
    "        defined_column_name = [\"Comment_Number\",\n",
    "                               \"Commenter_Username\",\n",
    "                               \"Comment\",\n",
    "                               \"Comment_Post_Time\",\n",
    "                               \"Overall_CB_Status\",\n",
    "                               \"CB_Type\",\n",
    "                               \"Sexual_Type1\", \"Unnamed_1\", \"Unnamed_2\",\n",
    "                               \"Sexual_Type2\", \"Unnamed_3\", \"Unnamed_4\",\n",
    "                               \"Physical_Appearance\", \"Unnamed_5\", \"Unnamed_6\",\n",
    "                               \"Race\", \"Unnamed_7\", \"Unnamed_8\",\n",
    "                               \"Intellectual\", \"Unnamed_9\", \"Unnamed_10\",\n",
    "                               \"Religious\", \"Unnamed_11\", \"Unnamed_12\",\n",
    "                               \"General_Hate\", \"Unnamed_13\", \"Unnamed_14\",\n",
    "                               \"Purpose_of_CB\",\n",
    "                               \"Insult\", \"Unnamed_15\", \"Unnamed_16\",\n",
    "                               \"Defensive\", \"Unnamed_17\", \"Unnamed_18\",\n",
    "                               \"Directionality\", \n",
    "                               \"Directed_Username\", \"Unnamed_19\", \"Unnamed_20\",\n",
    "                               \"Other_Aspects\",\n",
    "                               \"Depression\", \"Unnamed_21\", \"Unnamed_22\",\n",
    "                               \"Suicides\", \"Unnamed_23\", \"Unnamed_24\",\n",
    "                               \"Stress\", \"Unnamed_25\", \"Unnamed_26\",\n",
    "                               \"Discrimination\", \"Unnamed_27\", \"Unnamed_28\"]\n",
    "        \n",
    "        for sheet_name in sheet_names:\n",
    "            # Retrive the dataframe for that specific sheet name\n",
    "            dataframe[sheet_name] = pd.read_excel(excel_file, sheet_name)\n",
    "            \n",
    "            # Redefine the columns' name based on the defined_column_name\n",
    "            try:\n",
    "                dataframe[sheet_name].columns = defined_column_name\n",
    "            except:\n",
    "                print(f'{filename} : {sheet_name}.')\n",
    "                \n",
    "        \n",
    "        for item in dataframe.values():\n",
    "            # Drop the first two rows of the dataframe due to formatting issue\n",
    "            item = item.drop(item.index[:2])\n",
    "            \n",
    "            # Drop unnecessary attributes/columns from the dataframe\n",
    "            columns_to_drop = [col for col in item.columns if any(substring in col for substring in [\"Comment_Number\",\n",
    "                                                                                                     \"Unnamed\",\n",
    "                                                                                                     \"Commenter_Username\",\n",
    "                                                                                                     \"Comment_Post_Time\",\n",
    "                                                                                                     \"CB_Type\", \n",
    "                                                                                                     \"Purpose_of_CB\",\n",
    "                                                                                                     \"Insult\",\n",
    "                                                                                                     \"Religious\",\n",
    "                                                                                                     \"Defensive\",\n",
    "                                                                                                     \"Other_Aspects\",\n",
    "                                                                                                     'Suicides',\n",
    "                                                                                                     \"Stress\",\n",
    "                                                                                                     \"Depression\",\n",
    "                                                                                                     \"Discrimination\",\n",
    "                                                                                                     \"Directionality\", \n",
    "                                                                                                    \"Directed_Username\"])]\n",
    "\n",
    "            data = item.drop(columns=columns_to_drop)\n",
    "            # Store the data to extracted_df\n",
    "            extracted_df.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfe028-21b5-4aa7-ac15-00c82375f3a9",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this stage, we will perform the following tasks:\n",
    "* Remove any rows that contains duplicate items and empty values for 'Comment' attribute\n",
    "* Missing values in the attributes, any missing values will be replaced by 0. Two assumption are made:\n",
    "    - All the cyberbullying texts in the provided original datasets have been correctly labelled as 1. Therefore, the remaining data with NA values will be labelled as 0 which is not a cyberbullying text.\n",
    "    - All the cyberbullying texts in the provided original datasets have been correctly assigned to their respective cyberbullying type by labelling as 1. Therefore, the remaining cyberbullying type will be labelled as 0\n",
    "* Check for error data\n",
    "* Text formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b5f86-ef46-4cf3-b748-e499f98a7cd8",
   "metadata": {},
   "source": [
    "### Removal of duplicate items and empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "63fb6f2c-d1cb-41af-8818-4e05feeb5124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate all the filtered dataframes into one\n",
    "df = pd.concat(extracted_df, ignore_index=True)\n",
    "\n",
    "# Removal of duplicates items in the 'Comment' column\n",
    "df = df.drop_duplicates(subset='Comment')\n",
    "\n",
    "# Removal of empty value in the 'Comment' column\n",
    "df = df.dropna(subset='Comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf7a64-a08e-4844-965a-a6c13d9eb2a6",
   "metadata": {},
   "source": [
    "### Replacing NA values for 'Overall_CB_Status' attribute and CB type's attributes\n",
    "Two assumption are made:\n",
    "* All the cyberbullying texts in the provided original datasets have been correctly labelled as 1. Therefore, the remaining data with NA values will be labelled as 0 which is not a cyberbullying text.\n",
    "* All the cyberbullying texts in the provided original datasets have been correctly assigned to their respective cyberbullying type by labelling as 1. Therefore, the remaining cyberbullying type will be labelled as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "85b7ffec-8f2e-4f6f-a10d-472e6bb1b483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA values found in the DataFrame. Replacing NA values with 0......\n",
      "No NA values founds in the datasets.\n"
     ]
    }
   ],
   "source": [
    "# Check if NA value exists in the concatenated dataframe\n",
    "check_na = df.isna()\n",
    "max_retries = 2\n",
    "retry_count = 0\n",
    "\n",
    "# Replace NA value to 0 if exists in the dataframe\n",
    "while (check_na == True).any().any() and retry_count < max_retries:\n",
    "    print(\"NA values found in the DataFrame. Replacing NA values with 0......\")            \n",
    "    df = df.fillna(0)\n",
    "    check_na = df.isna()\n",
    "    retry_count += 1\n",
    "          \n",
    "if (check_na == True).any().any():\n",
    "    print(\"Maximum retries reached. Some NA values could not be replaced.\")\n",
    "else:\n",
    "    print(\"No NA values founds in the datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f2348-5dbd-4bdf-97fc-67fa1534cc7d",
   "metadata": {},
   "source": [
    "### Check for Attribute's Data Type\n",
    "According to the attributes' characteristics, all attributes should be in int (1 : True and 0 : False) with the exceptions for 'Comment' which should be in string/object type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "57c1c813-13f2-4247-88b8-9919bd922892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment                object\n",
       "Overall_CB_Status       int64\n",
       "Sexual_Type1           object\n",
       "Sexual_Type2            int64\n",
       "Physical_Appearance     int64\n",
       "Race                   object\n",
       "Intellectual            int64\n",
       "General_Hate           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for dataframe's data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf221a-8cb6-4d55-a7c1-3f86b1e6caac",
   "metadata": {},
   "source": [
    "Referring to the above output, attributes like Sexual_Type1, Race and General_Hate needs to be converted into int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "674649d1-5634-42f9-bb2d-b1f30774d57c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment                object\n",
      "Overall_CB_Status       int64\n",
      "Sexual_Type1            int64\n",
      "Sexual_Type2            int64\n",
      "Physical_Appearance     int64\n",
      "Race                    int64\n",
      "Intellectual            int64\n",
      "General_Hate            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "selected_column_to_convert = ['Sexual_Type1', 'Race', 'General_Hate']\n",
    "\n",
    "# Performing data type conversion according to their attributes\n",
    "for column_name in selected_column_to_convert:\n",
    "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce').fillna(0)\n",
    "    df[column_name] = df[column_name].astype('int64')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556acba5-6a37-477a-90c6-1ad2ad51817c",
   "metadata": {},
   "source": [
    "Referring to the above output, all attributes are now following the right data type after the conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb9a6b9-d21a-4565-8c68-f144f83a58d5",
   "metadata": {},
   "source": [
    "### Check for Error Data\n",
    "Since all attributes with the exception of 'Comments' are in int (1 : True, 0 : False), and thus the min and max value within the attribute should be either 0 or 1 only.\n",
    "\n",
    "Any error data will be removed from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f97b9d70-216a-4f3c-9d4e-5e781f9bab0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_CB_Status</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "      <td>7942.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.028834</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>0.068371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.341885</td>\n",
       "      <td>0.167350</td>\n",
       "      <td>0.115295</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>0.116352</td>\n",
       "      <td>0.137462</td>\n",
       "      <td>0.252397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Overall_CB_Status  Sexual_Type1  Sexual_Type2  Physical_Appearance  \\\n",
       "count        7942.000000   7942.000000   7942.000000          7942.000000   \n",
       "mean            0.134097      0.028834      0.013473             0.019391   \n",
       "std             0.341885      0.167350      0.115295             0.137902   \n",
       "min             0.000000      0.000000      0.000000             0.000000   \n",
       "25%             0.000000      0.000000      0.000000             0.000000   \n",
       "50%             0.000000      0.000000      0.000000             0.000000   \n",
       "75%             0.000000      0.000000      0.000000             0.000000   \n",
       "max             3.000000      1.000000      1.000000             1.000000   \n",
       "\n",
       "              Race  Intellectual  General_Hate  \n",
       "count  7942.000000   7942.000000   7942.000000  \n",
       "mean      0.013725      0.019265      0.068371  \n",
       "std       0.116352      0.137462      0.252397  \n",
       "min       0.000000      0.000000      0.000000  \n",
       "25%       0.000000      0.000000      0.000000  \n",
       "50%       0.000000      0.000000      0.000000  \n",
       "75%       0.000000      0.000000      0.000000  \n",
       "max       1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c1e72-8310-4e98-a87d-191580687f8d",
   "metadata": {},
   "source": [
    "For 'Overall_CB_Status' attribute, it contains value larger than 1. Therefore, the respective rows with value greater than 1 should be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "90beadee-9243-4788-8629-7480dae9d82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_CB_Status</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7941.000000</td>\n",
       "      <td>7941.000000</td>\n",
       "      <td>7941.000000</td>\n",
       "      <td>7941.000000</td>\n",
       "      <td>7941.000000</td>\n",
       "      <td>7941.000000</td>\n",
       "      <td>7941.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.133736</td>\n",
       "      <td>0.028838</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.019393</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.068379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.340390</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>0.115302</td>\n",
       "      <td>0.137911</td>\n",
       "      <td>0.116359</td>\n",
       "      <td>0.137471</td>\n",
       "      <td>0.252412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Overall_CB_Status  Sexual_Type1  Sexual_Type2  Physical_Appearance  \\\n",
       "count        7941.000000   7941.000000   7941.000000          7941.000000   \n",
       "mean            0.133736      0.028838      0.013474             0.019393   \n",
       "std             0.340390      0.167361      0.115302             0.137911   \n",
       "min             0.000000      0.000000      0.000000             0.000000   \n",
       "25%             0.000000      0.000000      0.000000             0.000000   \n",
       "50%             0.000000      0.000000      0.000000             0.000000   \n",
       "75%             0.000000      0.000000      0.000000             0.000000   \n",
       "max             1.000000      1.000000      1.000000             1.000000   \n",
       "\n",
       "              Race  Intellectual  General_Hate  \n",
       "count  7941.000000   7941.000000   7941.000000  \n",
       "mean      0.013726      0.019267      0.068379  \n",
       "std       0.116359      0.137471      0.252412  \n",
       "min       0.000000      0.000000      0.000000  \n",
       "25%       0.000000      0.000000      0.000000  \n",
       "50%       0.000000      0.000000      0.000000  \n",
       "75%       0.000000      0.000000      0.000000  \n",
       "max       1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows in Overall_CB_Status attriute where the value is not 0 or 1\n",
    "df = df[df['Overall_CB_Status'].isin([0, 1])]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a97622-273f-45ec-861d-8f3cff5dfa35",
   "metadata": {},
   "source": [
    "### Text Formatting\n",
    "For text formatting, we are using the following techniques:\n",
    "* to convert the comments into lowercase\n",
    "* to remove any tagged user id and hashtag info from the comments\n",
    "* to remove any URL link in the comments\n",
    "* to separate digit from the comments' words\n",
    "* to remove digits from the comments\n",
    "* to replace contractions found in the comments\n",
    "* to replace any abbreviation words found in the comments\n",
    "* to replace emoticons from the comments with words\n",
    "* to remove punctuation\n",
    "* to remove repeated character in a word with a max allowable repetition of 2 from the comments\n",
    "* to remove single character word found in the comments\n",
    "* to remove common stop words from the comments\n",
    "* to remove any character that is not a letter, digit, or whitespace\n",
    "* to remove additional white spaces\n",
    "* to conduct spell checking\n",
    "* to remove any rows that do not contain single word in the comments\n",
    "* to remove any rows that do not contain any english words\n",
    "* to conduct word lemmatization on the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c3af361f-29b2-49e6-bae2-04e32ab84168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To convert the text into lowercase\n",
    "def text_to_lower(text):\n",
    "    if isinstance (text, str):\n",
    "        lower_text = str(text.lower())\n",
    "    else:\n",
    "        lower_text = str(text)\n",
    "    return lower_text\n",
    "\n",
    "# To remove any tagged user id and hashtag info\n",
    "def remove_words_start_with(text, starts_with_char):\n",
    "    urls = re.finditer(starts_with_char + r'[A-Za-z0-9\\w]*', text)\n",
    "    for i in urls:\n",
    "        text = re.sub(i.group().strip(), '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# To remove any URL link\n",
    "def remove_words_ending_with_com(text):\n",
    "    # Define a regular expression pattern to match words ending with \".com\"\n",
    "    pattern = r'\\b\\w+\\.com\\b'\n",
    "    # Use the re.sub function to replace all matches with an empty string\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# To separate digit from text\n",
    "def separate_digit_text(text):\n",
    "    regex_patter = re.compile(r'([\\d]+)([a-zA-Z]+)')\n",
    "    clean_text = regex_patter.sub(r'\\1 \\2', text)\n",
    "    return clean_text\n",
    "\n",
    "# To remove digits from the text\n",
    "def removal_of_digits(text):\n",
    "    regex_pattern = re.compile(r'[0-9]')\n",
    "    text = regex_pattern.sub('', text)\n",
    "    return text\n",
    "\n",
    "# To replace contraction\n",
    "def appos_look_up(text):\n",
    "    words = text.split()\n",
    "    new_text = []\n",
    "    for word in words:\n",
    "        word_s = word.lower()\n",
    "        if word_s in appos_dict:\n",
    "            new_text.append(appos_dict[word_s])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    apposed = \" \".join(new_text)\n",
    "    return apposed\n",
    "\n",
    "# To replace any abbreviation words found in the text\n",
    "def slang_look_up(text):\n",
    "    words = text.split()\n",
    "    new_text = []\n",
    "\n",
    "    for word in words:\n",
    "        word_s = word.lower()\n",
    "        if word_s in slangs_dict:\n",
    "            new_text.append(slangs_dict[word_s])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    slanged = \" \".join(new_text)\n",
    "    return slanged\n",
    "\n",
    "# To replace emoticons with text\n",
    "def emoticons_look_up(text):\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in emoticons:\n",
    "            text = text.replace(word, emoticons[word])\n",
    "    return text\n",
    "\n",
    "# To remove punctuations\n",
    "def remove_punctuations(text):\n",
    "    regex_pattern = re.compile(r'[\\,+\\:\\?\\!\\\"\\(\\)!\\'\\.\\%\\[\\]]+')\n",
    "    clean_text = regex_pattern.sub(r' ', text)\n",
    "    clean_text = clean_text.replace('-', '')\n",
    "    return clean_text\n",
    "\n",
    "# To remove repeated character in a word with a max allowable repetition of 2\n",
    "def remove_repeated_characters(text):\n",
    "    \"\"\"\n",
    "    Remove repeated characters (>2) in words to max limit of 2\n",
    "    Example: I am verrry happpyyy today => I am verry happyy today\n",
    "    Args:\n",
    "        text (str): text\n",
    "    Returns:\n",
    "        clean_text (str): cleaned text with removed repeated chars\n",
    "    \"\"\"\n",
    "    regex_pattern = re.compile(r'(.)\\1+')\n",
    "    text = regex_pattern.sub(r'\\1\\1', text)\n",
    "    return text\n",
    "\n",
    "# To remove a single character word\n",
    "def remove_single_char_word(text):\n",
    "    words = text.split()\n",
    "    filter_words = [word for word in words if len(word) > 1]\n",
    "    return \" \".join(filter_words)\n",
    "\n",
    "# To remove common stop words\n",
    "def remove_stop_words(text, stop_words=stopwords_default):\n",
    "    stop_words = set(stopwords_default)\n",
    "    split_list = text.split(\" \")\n",
    "    split_list = [word for word in split_list if word not in stop_words]\n",
    "    return \" \".join(split_list)\n",
    "\n",
    "# To remove any character that is not a letter, digit, or whitespace\n",
    "def removal_non_letter_digit_whitespaces(text):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'  \n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# To remove additional white space\n",
    "def remove_extra_space(text):\n",
    "    clean_text = ' '.join(text.strip().split())\n",
    "    return clean_text\n",
    "\n",
    "def check_word_spelling(text):\n",
    "    # Initialize the spell checker\n",
    "    spell = SpellChecker()\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    # Create a dictionary to store misspelled words and their corrected versions\n",
    "    misspelled_dict = {}\n",
    "\n",
    "    # Iterate through the words in the text\n",
    "    for word in words:\n",
    "        # Check if the word is misspelled\n",
    "        if word in spell.unknown(words):\n",
    "            # Get the one `most likely` correction\n",
    "            corrected_word = spell.correction(word)\n",
    "            # Store the misspelled word and its correction in the dictionary\n",
    "            misspelled_dict[word] = corrected_word\n",
    "\n",
    "    # Replace misspelled words with their corrected versions in the text\n",
    "    for misspelled, corrected in misspelled_dict.items():\n",
    "        if corrected is not None:\n",
    "            text = text.replace(misspelled, corrected)\n",
    "\n",
    "    return text\n",
    "\n",
    "# To check if the rows consist any english words\n",
    "def any_english_word_in_list(text):\n",
    "    word_list = word_tokenize(text)\n",
    "    english_words = set(words.words())\n",
    "    return any(word.lower() in english_words for word in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "35be87d8-81de-4976-90e0-914c42a9aff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To create a copy of the df to text_formatting\n",
    "text_formatting = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "83e88af1-ab67-4498-90c7-4f9471f08eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : text_to_lower(x))\n",
    "starts_with_char_list = ['@', '#']\n",
    "for char in starts_with_char_list:\n",
    "    text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : remove_words_start_with(x,starts_with_char=char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c4fca457-905b-4def-9849-4a21a8a4ce0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of functions to apply\n",
    "functions_to_apply = [\n",
    "    remove_words_ending_with_com,\n",
    "    separate_digit_text,\n",
    "    removal_of_digits,\n",
    "    appos_look_up,\n",
    "    slang_look_up,\n",
    "    emoticons_look_up,\n",
    "    remove_punctuations,\n",
    "    remove_repeated_characters,\n",
    "    remove_single_char_word,\n",
    "    remove_stop_words,\n",
    "    removal_non_letter_digit_whitespaces,\n",
    "    remove_extra_space,\n",
    "]\n",
    "\n",
    "# Apply functions in a loop\n",
    "for func in functions_to_apply:\n",
    "    text_formatting['Comment'] = text_formatting['Comment'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "bb64cb60-1346-4a79-9d63-8dc6d1c13b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To remove any rows with empty value in the Comment attribute prior to conduct spell checking\n",
    "text_formatting = text_formatting[text_formatting['Comment'] != '']\n",
    "text_formatting['Comment'] = text_formatting['Comment'].apply(lambda x : check_word_spelling(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "724b6076-6d56-434f-aa28-0942c08b3a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To conduct word lemmatizer and save the result as a new column\n",
    "lematizer=WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_words(text):\n",
    "    return \" \".join([lematizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "result = list(text_formatting['Comment'].apply(lambda x : lemmatizer_words(x)))\n",
    "\n",
    "index_to_insert = 1\n",
    "new_column_name = \"Lemmatized_Comment\"\n",
    "final_df = text_formatting.copy()\n",
    "final_df.insert(index_to_insert, new_column_name, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "94aad748-edc1-4faa-aec6-73f09ea3a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with at least one English word in the list\n",
    "clean_df = final_df[final_df['Lemmatized_Comment'].apply(lambda x: any_english_word_in_list(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b021a7d1-f8e1-4627-b621-cd2a163de97e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmatized_Comment</th>\n",
       "      <th>Overall_CB_Status</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>larry</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get gif cannot have phone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>larry zany sexy niall liam something stupid back</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretty much</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>daisy one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>damn really want one booty argentina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>want blue whale one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>rainbow leopard print one love much restock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6329 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Lemmatized_Comment  Overall_CB_Status  \\\n",
       "0                                                 zany                  0   \n",
       "1                                                larry                  0   \n",
       "3                            get gif cannot have phone                  0   \n",
       "4     larry zany sexy niall liam something stupid back                  0   \n",
       "7                                          pretty much                  0   \n",
       "...                                                ...                ...   \n",
       "8495                                         daisy one                  0   \n",
       "8496              damn really want one booty argentina                  0   \n",
       "8497                               want blue whale one                  0   \n",
       "8498                                            puzzle                  0   \n",
       "8499       rainbow leopard print one love much restock                  0   \n",
       "\n",
       "      Sexual_Type1  Sexual_Type2  Physical_Appearance  Race  Intellectual  \\\n",
       "0                0             0                    0     0             0   \n",
       "1                0             0                    0     0             0   \n",
       "3                0             0                    0     0             0   \n",
       "4                0             0                    0     0             0   \n",
       "7                0             0                    0     0             0   \n",
       "...            ...           ...                  ...   ...           ...   \n",
       "8495             0             0                    0     0             0   \n",
       "8496             0             0                    0     0             0   \n",
       "8497             0             0                    0     0             0   \n",
       "8498             0             0                    0     0             0   \n",
       "8499             0             0                    0     0             0   \n",
       "\n",
       "      General_Hate  \n",
       "0                0  \n",
       "1                0  \n",
       "3                0  \n",
       "4                0  \n",
       "7                0  \n",
       "...            ...  \n",
       "8495             0  \n",
       "8496             0  \n",
       "8497             0  \n",
       "8498             0  \n",
       "8499             0  \n",
       "\n",
       "[6329 rows x 8 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_drop = ['Comment', 'Overall_CB_Status']\n",
    "final_df = clean_df.drop(columns=column_to_drop)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0232f543-5ad2-4f16-8393-23cbe412bc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the final_df into a .csv file\n",
    "file_path = \"./preprocess_data.csv\"\n",
    "final_df.to_csv(file_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e20198-9bbb-46b7-8705-9b8c6768ee80",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8d00b1fc-6708-4ebc-8ef2-8f8d67ac51aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmatized_Comment</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>larry</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get gif cannot have phone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>larry zany sexy niall liam something stupid back</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6324</th>\n",
       "      <td>daisy one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>damn really want one booty argentina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6326</th>\n",
       "      <td>want blue whale one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>rainbow leopard print one love much restock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6329 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Lemmatized_Comment  Sexual_Type1  \\\n",
       "0                                                 zany             0   \n",
       "1                                                larry             0   \n",
       "2                            get gif cannot have phone             0   \n",
       "3     larry zany sexy niall liam something stupid back             0   \n",
       "4                                          pretty much             0   \n",
       "...                                                ...           ...   \n",
       "6324                                         daisy one             0   \n",
       "6325              damn really want one booty argentina             0   \n",
       "6326                               want blue whale one             0   \n",
       "6327                                            puzzle             0   \n",
       "6328       rainbow leopard print one love much restock             0   \n",
       "\n",
       "      Sexual_Type2  Physical_Appearance  Race  Intellectual  General_Hate  \n",
       "0                0                    0     0             0             0  \n",
       "1                0                    0     0             0             0  \n",
       "2                0                    0     0             0             0  \n",
       "3                0                    0     0             0             0  \n",
       "4                0                    0     0             0             0  \n",
       "...            ...                  ...   ...           ...           ...  \n",
       "6324             0                    0     0             0             0  \n",
       "6325             0                    0     0             0             0  \n",
       "6326             0                    0     0             0             0  \n",
       "6327             0                    0     0             0             0  \n",
       "6328             0                    0     0             0             0  \n",
       "\n",
       "[6329 rows x 7 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./preprocess_data.csv\"\n",
    "df =pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "370de208-40a6-4f32-b721-9c606d8c9403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6104\n",
      "1     225\n",
      "Name: Sexual_Type1, dtype: int64\n",
      "0    6223\n",
      "1     106\n",
      "Name: Sexual_Type2, dtype: int64\n",
      "0    6177\n",
      "1     152\n",
      "Name: Physical_Appearance, dtype: int64\n",
      "0    6224\n",
      "1     105\n",
      "Name: Race, dtype: int64\n",
      "0    6178\n",
      "1     151\n",
      "Name: Intellectual, dtype: int64\n",
      "0    5803\n",
      "1     526\n",
      "Name: General_Hate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_columns_balancing = ['Sexual_Type1', 'Sexual_Type2', 'Physical_Appearance', 'Race', 'Intellectual', 'General_Hate']\n",
    "for column in selected_columns_balancing:\n",
    "    result = df[column].value_counts()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58f34d-3aba-4c65-9cec-0f25b47968a5",
   "metadata": {},
   "source": [
    "## Data Balancing Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "738b96fa-f1fd-4dc4-a857-fef551eba380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemmatized_Comment</th>\n",
       "      <th>Sexual_Type1</th>\n",
       "      <th>Sexual_Type2</th>\n",
       "      <th>Physical_Appearance</th>\n",
       "      <th>Race</th>\n",
       "      <th>Intellectual</th>\n",
       "      <th>General_Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>larry</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get gif cannot have phone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>larry zany sexy niall liam something stupid back</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty much</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>daisy one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>damn really want one booty argentina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>want blue whale one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>puzzle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>rainbow leopard print one love much restock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5402 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Lemmatized_Comment  Sexual_Type1  \\\n",
       "0                                                 zany             0   \n",
       "1                                                larry             0   \n",
       "2                            get gif cannot have phone             0   \n",
       "3     larry zany sexy niall liam something stupid back             0   \n",
       "4                                          pretty much             0   \n",
       "...                                                ...           ...   \n",
       "5397                                         daisy one             0   \n",
       "5398              damn really want one booty argentina             0   \n",
       "5399                               want blue whale one             0   \n",
       "5400                                            puzzle             0   \n",
       "5401       rainbow leopard print one love much restock             0   \n",
       "\n",
       "      Sexual_Type2  Physical_Appearance  Race  Intellectual  General_Hate  \n",
       "0                0                    0     0             0             0  \n",
       "1                0                    0     0             0             0  \n",
       "2                0                    0     0             0             0  \n",
       "3                0                    0     0             0             0  \n",
       "4                0                    0     0             0             0  \n",
       "...            ...                  ...   ...           ...           ...  \n",
       "5397             0                    0     0             0             0  \n",
       "5398             0                    0     0             0             0  \n",
       "5399             0                    0     0             0             0  \n",
       "5400             0                    0     0             0             0  \n",
       "5401             0                    0     0             0             0  \n",
       "\n",
       "[5402 rows x 7 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_cb = df[(df['Sexual_Type1'] == 0) & \n",
    "              (df['Sexual_Type2'] == 0) & \n",
    "              (df['Physical_Appearance'] == 0) & \n",
    "              (df['Race'] == 0) & \n",
    "              (df['Intellectual'] == 0) &\n",
    "              (df['General_Hate'] == 0)].reset_index(drop=True)\n",
    "df_no_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c83b0226-f59a-459f-901c-48bb32a0a79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_df_no_cb = df_no_cb.sample(n=3000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "75d9d4d0-85e7-4925-97c6-0ad1032b496e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and label\n",
    "selected_columns_balancing = ['Sexual_Type1', 'Sexual_Type2', 'Physical_Appearance', 'Race', 'Intellectual', 'General_Hate']\n",
    "\n",
    "balanced_df = sampled_df_no_cb.copy()\n",
    "for column in selected_columns_balancing:\n",
    "    X = df['Lemmatized_Comment']\n",
    "    y = df[column]\n",
    "    # Reshape X to a 2D array\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    # Reshape y to a 2D array\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    # Set the desired number of oversampled instances\n",
    "    desired_samples = 600  # Change this to your desired number\n",
    "\n",
    "    # Calculate the sampling strategy\n",
    "    minority_class_count = np.sum(y == 1)\n",
    "    sampling_strategy = {0: len(y) - minority_class_count, 1: desired_samples}\n",
    "\n",
    "    # Initialize RandomOverSampler with the specified sampling strategy\n",
    "    ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    \n",
    "    # Perform oversampling\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    # Convert y_resampled back to a 1D array\n",
    "    y_resampled = y_resampled.flatten()\n",
    "    # Convert X_resampled back to a 1D array of comments\n",
    "    X_resampled = X_resampled.flatten()\n",
    "\n",
    "    # Create a new dictionary for oversampled data\n",
    "    oversampled_data = {\n",
    "        'Lemmatized_Comment': list(X_resampled),\n",
    "        column: list(y_resampled),\n",
    "    }\n",
    "\n",
    "    oversampled_df = pd.DataFrame(oversampled_data)\n",
    "    oversampled_df = oversampled_df[oversampled_df[column] == 1]\n",
    "    balanced_df = pd.concat([balanced_df, oversampled_df], ignore_index=True)\n",
    "    balanced_df = balanced_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a596c5fe-4d24-43f3-a2a0-075c27091a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    6000\n",
      "1.0     600\n",
      "Name: Sexual_Type1, dtype: int64\n",
      "0.0    6000\n",
      "1.0     600\n",
      "Name: Sexual_Type2, dtype: int64\n",
      "0.0    6000\n",
      "1.0     600\n",
      "Name: Physical_Appearance, dtype: int64\n",
      "0.0    6000\n",
      "1.0     600\n",
      "Name: Race, dtype: int64\n",
      "0.0    6000\n",
      "1.0     600\n",
      "Name: Intellectual, dtype: int64\n",
      "0.0    6000\n",
      "1.0     600\n",
      "Name: General_Hate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_columns_balancing = ['Sexual_Type1', 'Sexual_Type2', 'Physical_Appearance', 'Race', 'Intellectual', 'General_Hate']\n",
    "for column in selected_columns_balancing:\n",
    "    balanced_df.drop_duplicates(subset='Lemmatized_Comment')\n",
    "    result = balanced_df[column].value_counts()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f1b30460-6272-49e7-a2eb-47ae405c8588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized_Comment     object\n",
      "Sexual_Type1            int64\n",
      "Sexual_Type2            int64\n",
      "Physical_Appearance     int64\n",
      "Race                    int64\n",
      "Intellectual            int64\n",
      "General_Hate            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "selected_columns_balancing = ['Sexual_Type1', 'Sexual_Type2', 'Physical_Appearance', 'Race', 'Intellectual', 'General_Hate']\n",
    "\n",
    "# Performing data type conversion according to their attributes\n",
    "for column_name in selected_columns_balancing:\n",
    "    balanced_df[column_name] = pd.to_numeric(balanced_df[column_name], errors='coerce').fillna(0)\n",
    "    balanced_df[column_name] = balanced_df[column_name].astype('int64')\n",
    "print(balanced_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "fa6b061b-f2bd-4566-a70f-e4a01791c9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"./balanced_data_type1.csv\"\n",
    "balanced_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06813d-c2fe-47f5-ab03-2810ab665c6e",
   "metadata": {},
   "source": [
    "## Data Balancing Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2bbc96f6-df3e-43bd-bd1b-e20dc8d15c01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and label\n",
    "selected_columns_balancing = ['Sexual_Type1', 'Sexual_Type2', 'Physical_Appearance', 'Race', 'Intellectual', 'General_Hate']\n",
    "\n",
    "balanced_df = df.copy()\n",
    "for column in selected_columns_balancing:\n",
    "    X = df['Lemmatized_Comment']\n",
    "    y = df[column]\n",
    "    # Reshape X to a 2D array\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    # Reshape y to a 2D array\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    # Initialize RandomOverSampler\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "    # Perform oversampling\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "    # Initialize RandomOverSampler\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    \n",
    "    # Perform oversampling\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    # Convert y_resampled back to a 1D array\n",
    "    y_resampled = y_resampled.flatten()\n",
    "    # Convert X_resampled back to a 1D array of comments\n",
    "    X_resampled = X_resampled.flatten()\n",
    "\n",
    "    # Create a new dictionary for oversampled data\n",
    "    oversampled_data = {\n",
    "        'Lemmatized_Comment': list(X_resampled),\n",
    "        column: list(y_resampled),\n",
    "    }\n",
    "\n",
    "    oversampled_df = pd.DataFrame(oversampled_data)\n",
    "    oversampled_df = oversampled_df[oversampled_df[column].index > 6328]\n",
    "    balanced_df = pd.concat([balanced_df, oversampled_df], ignore_index=True)\n",
    "    balanced_df = balanced_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "cfe34999-1296-4240-bedc-cc22542ad57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    35669\n",
      "1.0     6104\n",
      "Name: Sexual_Type1, dtype: int64\n",
      "0.0    35550\n",
      "1.0     6223\n",
      "Name: Sexual_Type2, dtype: int64\n",
      "0.0    35596\n",
      "1.0     6177\n",
      "Name: Physical_Appearance, dtype: int64\n",
      "0.0    35549\n",
      "1.0     6224\n",
      "Name: Race, dtype: int64\n",
      "0.0    35595\n",
      "1.0     6178\n",
      "Name: Intellectual, dtype: int64\n",
      "0.0    35970\n",
      "1.0     5803\n",
      "Name: General_Hate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_columns_balancing = ['Sexual_Type1', 'Sexual_Type2', 'Physical_Appearance', 'Race', 'Intellectual', 'General_Hate']\n",
    "for column in selected_columns_balancing:\n",
    "    balanced_df.drop_duplicates(subset='Lemmatized_Comment')\n",
    "    result = balanced_df[column].value_counts()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e39a0031-05a3-41c0-ba53-fa0dee5b0ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"./balanced_data_type2.csv\"\n",
    "balanced_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98703cab-e341-4d6a-80a9-d8598772db03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
